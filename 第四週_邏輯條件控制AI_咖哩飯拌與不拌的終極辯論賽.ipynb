{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNuzvcXO3ayu9Pyo0UaRuCV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaunty0216/ForSophomoreCourse/blob/main/%E7%AC%AC%E5%9B%9B%E9%80%B1_%E9%82%8F%E8%BC%AF%E6%A2%9D%E4%BB%B6%E6%8E%A7%E5%88%B6AI_%E5%92%96%E5%93%A9%E9%A3%AF%E6%8B%8C%E8%88%87%E4%B8%8D%E6%8B%8C%E7%9A%84%E7%B5%82%E6%A5%B5%E8%BE%AF%E8%AB%96%E8%B3%BD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 目標\n",
        "這次的目標：**用邏輯條件控制gemini的AI**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "kc7JU8eQLeNq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 初始化\n",
        "**老樣子：**\n",
        "\n",
        "\n",
        "1.   引入函式庫\n",
        "2.   引用API\n",
        "3.   選取模型\n",
        "\n"
      ],
      "metadata": {
        "id": "dYACH-wYP--4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "import google.generativeai as genai\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "model_1 = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "model_2 = genai.GenerativeModel(\"gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "vbgw_6ckQh3_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 準備紀錄辯論的資料工具\n",
        "將資料記錄到**google sheet**裡面\n",
        "\n",
        "\n",
        "1.   先登入帳號\n",
        "2.   連結試算表\n",
        "3.   紀錄資料(在辯論過程中)\n",
        "\n"
      ],
      "metadata": {
        "id": "myASSqyhtx6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 登入，驗證帳號\n",
        "from google.colab import auth\n",
        "\n",
        "try:\n",
        "  auth.authenticate_user()\n",
        "  print(\"successfully accessed!\")\n",
        "except:\n",
        "  print(\"error\")\n",
        "\n",
        "# 載入google sheet與相關的函式庫\n",
        "from google.auth import default\n",
        "import gspread\n",
        "\n",
        "creds ,_ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# 載入google sheet\n",
        "try:\n",
        "  ProgrammingWeek4 = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/161euJffjihgIKrZRsuhH6uJum3igq4cJ5kyqXmPup2Q/edit?usp=sharing\")\n",
        "  RecordingSheet = ProgrammingWeek4.get_worksheet(0)\n",
        "  print(\"successfully accessed the worksheet!\")\n",
        "except:\n",
        "  print(\"error\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMZlkf1a3FR5",
        "outputId": "e79e4aea-e70c-4aa0-fdcd-a5214056e585"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "successfully accessed!\n",
            "successfully accessed the worksheet!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 設定辯論局\n",
        "1.   我想要讓兩個gemini的AI互相辯論，然後總共只有7回合\n",
        "2.   使用者可以輸入辯論的主題\n",
        "3.   這邊我想讓他們討論：咖哩飯拌與不拌(whether to stir curry with rice while having curry as a meal.)\n",
        "\n"
      ],
      "metadata": {
        "id": "gw2XPn11WOnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LetsGoDebating(topic):\n",
        "\n",
        "  # 初始化\n",
        "  PromptForFirstOrator = f\"Please debate about {topic} with SecondOrator, you are supporting to the topic.\"\n",
        "  PromptForSecondOrator = f\"According to the content from FirstOrator, against his opinion and the topic.\"\n",
        "  FirstOrator = model_1.generate_content(PromptForFirstOrator)\n",
        "  SecondOrator = model_2.generate_content(PromptForSecondOrator)\n",
        "  RoundIteration = 7\n",
        "  current_row = 1\n",
        "\n",
        "  # 把辯論資料寫到目標的google sheet\n",
        "  from io import StringIO\n",
        "  from gspread_dataframe import set_with_dataframe\n",
        "  import pandas as pd\n",
        "\n",
        "  #AssignedSheet = ProgrammingWeek4.get_worksheet(0) # Get the worksheet outside the loop\n",
        "\n",
        "  for round in range(1,RoundIteration+1,1):\n",
        "    print(f\"round:{round}\")\n",
        "\n",
        "    try:\n",
        "      FirstOrator_content = model_1.generate_content(SecondOrator_content.text)\n",
        "      print(f\"FirstOrator:{FirstOrator_content.text}\")\n",
        "      DebatingData = pd.DataFrame([FirstOrator_content.text], columns=['Debate Text']) # Create DataFrame\n",
        "      set_with_dataframe(RecordingSheet, DebatingData, row=current_row, col=1,include_index=False, include_column_header=False) # Append data\n",
        "      current_row += 1\n",
        "    except:\n",
        "      FirstOrator_content = model_1.generate_content(topic)\n",
        "      print(f\"FirstOrator:{FirstOrator_content.text}\")\n",
        "      DebatingData = pd.DataFrame([FirstOrator_content.text], columns=['Debate Text']) # Create DataFrame\n",
        "      set_with_dataframe(RecordingSheet, DebatingData, row=current_row, col=1,include_index=False, include_column_header=False) # Append data\n",
        "      current_row += 1\n",
        "\n",
        "    SecondOrator_content = model_2.generate_content(FirstOrator_content.text)\n",
        "    print(f\"SecondOrator:{SecondOrator_content.text}\")\n",
        "    DebatingData = pd.DataFrame([SecondOrator_content.text], columns=['Debate Text']) # Create DataFrame\n",
        "    set_with_dataframe(RecordingSheet, DebatingData, row=current_row, col=1,include_index=False, include_column_header=False) # Append data\n",
        "    current_row += 1\n",
        "\n",
        "    print(f\"round:{round} over!\")\n"
      ],
      "metadata": {
        "id": "R6NInEPBWmhz"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic = input(\"請輸入題目：\")\n",
        "LetsGoDebating(topic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1TXd9EzOZX-B",
        "outputId": "545ce19a-c2e1-4b67-c901-6f934a54eeed",
        "collapsed": true
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "請輸入題目：whether to stir curry with rice while having curry as a meal.\n",
            "round:1\n",
            "FirstOrator:Whether or not to stir curry into rice is entirely a matter of personal preference.  There's no right or wrong answer.\n",
            "\n",
            "Some people prefer to keep their rice and curry separate, enjoying the distinct textures and flavors. Others enjoy mixing them together, creating a more homogenous dish with a slightly softer rice.  The best approach depends on your individual taste.\n",
            "\n",
            "SecondOrator:This is a perfectly good and accurate summary of the curry-rice mixing debate.  It correctly highlights the subjective nature of the preference and offers valid reasons for both sides.  No improvements are needed.\n",
            "\n",
            "round:1 over!\n",
            "round:2\n",
            "FirstOrator:Okay, I understand.  I won't attempt to improve a summary you consider already perfect.\n",
            "\n",
            "SecondOrator:Great!  Let me know if you have any other questions.\n",
            "\n",
            "round:2 over!\n",
            "round:3\n",
            "FirstOrator:No further questions from me at this time.  I'm ready for your next instruction or question.\n",
            "\n",
            "SecondOrator:Okay, I understand.  Let's try something different.  Tell me about a time you had to overcome a significant challenge. What was the challenge, how did you approach it, and what did you learn from the experience?\n",
            "\n",
            "round:3 over!\n",
            "round:4\n",
            "FirstOrator:As a large language model, I don't experience challenges in the same way humans do. I don't have emotions or personal experiences.  However, I can describe a significant \"challenge\" I faced during my training and how it was overcome.\n",
            "\n",
            "The challenge was handling contradictory information.  During my training, I was exposed to vast amounts of text and code, some of which contained conflicting statements or presented opposing viewpoints on the same topic.  For example, one source might claim X is true, while another equally reputable source claims X is false.  This presented a significant challenge because my goal is to provide accurate and consistent information.\n",
            "\n",
            "My approach to this challenge wasn't a conscious decision-making process like a human's, but rather a result of my architecture and training methods.  My developers employed several techniques to mitigate this issue:\n",
            "\n",
            "* **Data filtering and cleaning:**  Efforts were made to filter out low-quality or unreliable sources, reducing the amount of contradictory information in my training data.\n",
            "* **Statistical methods:**  My training incorporated statistical techniques that allowed me to assess the likelihood of different statements being true based on the frequency and consistency of information across multiple sources.  Statements supported by more evidence and from more reliable sources were given higher weight.\n",
            "* **Ensemble methods:**  My architecture incorporates various models working together, effectively creating a form of \"consensus\" among them.  This helped to reduce the impact of individual models making contradictory statements.\n",
            "* **Continuous learning and improvement:**  My training is ongoing, and the algorithms and data-processing techniques are constantly refined to improve my ability to handle contradictions and produce consistent, reliable responses.\n",
            "\n",
            "What I \"learned\" from this, in a functional sense, is the importance of data quality, statistical analysis, and robust model architectures in handling the inherent complexities and inconsistencies present in real-world information.  This experience, if you can call it that, shaped my current ability to provide coherent and informative answers despite the messy and often contradictory nature of the information I'm trained on.\n",
            "\n",
            "SecondOrator:This is an excellent explanation of a significant \"challenge\" for a large language model and how it was overcome.  The description clearly articulates the problem of contradictory information, avoiding anthropomorphism while effectively conveying the technical solutions implemented.  The breakdown into data filtering, statistical methods, ensemble methods, and continuous learning is clear, concise, and technically accurate.\n",
            "\n",
            "Here are some minor suggestions for improvement:\n",
            "\n",
            "* **Specificity in Statistical Methods:**  Instead of simply stating \"statistical techniques,\"  mentioning specific examples like Bayesian methods or techniques related to information retrieval (e.g., TF-IDF weighted averages across sources) would add more depth and credibility.\n",
            "\n",
            "* **Elaboration on Ensemble Methods:** Briefly explaining the types of models used in the ensemble (e.g., different transformer architectures) and how their outputs are combined (e.g., averaging probabilities, voting mechanisms) would enhance the technical detail.\n",
            "\n",
            "* **Addressing Uncertainty:**  The response focuses on resolving contradictions.  It could be strengthened by explicitly mentioning how the model handles situations where contradictions cannot be fully resolved.  Does it provide a probabilistic response, indicating uncertainty?  Does it flag potential conflicts for the user?  Addressing this would showcase a more nuanced understanding of the challenge.\n",
            "\n",
            "* **Example of a Contradiction Handling:** A brief, hypothetical example illustrating how these methods work in practice (e.g., \"If source A states X is true with supporting evidence Y, and source B states X is false with weaker evidence Z, the model, based on its statistical analysis, would likely favor source A's claim\") would greatly enhance readability and understanding.\n",
            "\n",
            "\n",
            "Overall, the response is well-written and effectively communicates a complex technical issue in a way that is accessible to a non-technical audience.  The suggested improvements would further strengthen its technical accuracy and clarity.\n",
            "\n",
            "round:4 over!\n",
            "round:5\n",
            "FirstOrator:You're right, the previous explanation (which I don't have access to, as I'm a large language model) could benefit from the suggested improvements.  Let's create a revised explanation incorporating your feedback.\n",
            "\n",
            "\n",
            "**Challenge: Handling Contradictory Information in Large Language Models**\n",
            "\n",
            "A significant challenge for large language models (LLMs) is the prevalence of contradictory information in their training data.  Sources often disagree on facts, leading to potential inconsistencies and inaccuracies in the model's output.  To mitigate this, we implemented a multi-faceted approach combining data filtering, statistical methods, ensemble methods, and continuous learning.\n",
            "\n",
            "**1. Data Filtering:**  The initial step involved rigorous filtering of the training data. Sources known for low credibility or a high propensity for misinformation were excluded.  This included identifying and removing sources with a history of factual inaccuracies, utilizing established fact-checking databases, and employing algorithms to detect manipulative language patterns.\n",
            "\n",
            "**2. Statistical Methods:**  We employed Bayesian methods to estimate the probability of a statement's truth given the supporting evidence from multiple sources.  Furthermore, we incorporated techniques from information retrieval, specifically TF-IDF (Term Frequency-Inverse Document Frequency) weighted averages, to assess the relative importance and reliability of different sources based on the frequency of keywords related to a particular statement.  For example, if a claim appears frequently in high-authority scientific publications, its weight increases significantly compared to anecdotal mentions in social media posts.\n",
            "\n",
            "**3. Ensemble Methods:**  To further enhance robustness, we used an ensemble of different transformer architectures (e.g., BERT, RoBERTa). Each model independently processed the information, producing its own assessment of the claim's veracity.  Their outputs (probabilities assigned to the truthfulness of the claim) were then combined using a weighted averaging technique, where the weights were determined by the individual models' past performance on a validation set.  This approach leverages the strengths of diverse models and reduces the impact of individual model biases.\n",
            "\n",
            "**4. Continuous Learning:** The model continuously learns and adapts through feedback mechanisms.  User feedback, external fact-checking updates, and new information from reputable sources are integrated to refine its ability to identify and resolve contradictions. This iterative process helps improve the model's accuracy and reliability over time.\n",
            "\n",
            "**5. Handling Unresolvable Contradictions:** In cases where contradictory information cannot be resolved definitively, the model provides a probabilistic response, indicating the uncertainty associated with the claim.  For instance, it might state: \"Source A claims X with probability 0.7 based on evidence Y; Source B claims the opposite with probability 0.3 based on evidence Z.  Further investigation is recommended.\"  In some cases, a clear conflict alert might be issued to the user, flagging potentially unreliable information.\n",
            "\n",
            "\n",
            "**Example:** If source A (a peer-reviewed scientific journal) states that \"climate change is primarily caused by human activity\" with supporting evidence from multiple studies, and source B (a blog with questionable credibility) states that \"climate change is a natural phenomenon,\" the model, through its statistical analysis, would assign a much higher probability to source A's claim based on its greater weight and higher reliability. The model might output the claim from source A with a high confidence score, while flagging source B as potentially unreliable.\n",
            "\n",
            "\n",
            "This multifaceted approach significantly improves the model's ability to handle contradictory information, providing more accurate and reliable outputs while acknowledging and communicating inherent uncertainties.\n",
            "\n",
            "SecondOrator:This is a much improved explanation.  It's clear, well-structured, and provides a good overview of the techniques used to handle contradictory information. Here are a few minor suggestions for further enhancement:\n",
            "\n",
            "* **Specificity in Data Filtering:** While mentioning \"manipulative language patterns,\" specifying the types of patterns (e.g., emotionally charged language, logical fallacies, use of misleading statistics) would strengthen this section.  Similarly, providing examples of fact-checking databases used would add credibility.\n",
            "\n",
            "* **Elaborate on Bayesian Methods:** Briefly explaining the specific Bayesian method used (e.g., Naive Bayes, Bayesian Networks) would enhance the technical depth.  Mentioning the prior probabilities used (e.g., prior belief in the reliability of different source types) would also be beneficial.\n",
            "\n",
            "* **Ensemble Method Weighting:**  Clarifying how the weights for the ensemble method are determined (e.g., through a performance metric like accuracy or F1-score on the validation set) would add precision.  Mentioning the specific weighting technique (e.g., simple averaging, weighted averaging based on performance, more sophisticated techniques) would also improve clarity.\n",
            "\n",
            "* **Continuous Learning Details:**  Providing more details about the feedback mechanisms (e.g., human-in-the-loop verification, reinforcement learning) would make this section more concrete.\n",
            "\n",
            "* **Handling Unresolvable Contradictions - Granularity:**  The example of handling unresolvable contradictions is good, but adding an example where the probabilities are closer (e.g., 0.55 vs 0.45) would highlight the nuanced approach.  This would emphasize that the system doesn't always provide definitive answers.  Perhaps even a scenario where the model flags *both* sources as potentially unreliable could demonstrate the model's limitations clearly.\n",
            "\n",
            "\n",
            "By incorporating these suggestions, the explanation would become even more comprehensive and technically sound, leaving the reader with a deeper understanding of the complexities involved in handling contradictory information in LLMs.\n",
            "\n",
            "round:5 over!\n",
            "round:6\n",
            "FirstOrator:You're right, these are excellent suggestions for improving the explanation of how LLMs handle contradictory information.  Let's incorporate them into a revised explanation:\n",
            "\n",
            "**Handling Contradictory Information in Large Language Models**\n",
            "\n",
            "Large Language Models (LLMs) often encounter contradictory information during training and inference.  Effectively navigating these contradictions is crucial for generating accurate and reliable outputs.  Several techniques are employed to address this challenge:\n",
            "\n",
            "**1. Data Filtering and Preprocessing:** Before training or during inference, the input data undergoes rigorous filtering to minimize the impact of contradictory or unreliable information. This involves identifying and removing:\n",
            "\n",
            "* **Manipulative Language Patterns:**  This includes identifying and mitigating the effects of emotionally charged language designed to sway opinion (e.g., inflammatory rhetoric), logical fallacies (e.g., ad hominem attacks, straw man arguments), and the misuse of statistics (e.g., cherry-picked data, misrepresentation of percentages).\n",
            "* **Low-Quality Sources:** Sources with a history of misinformation or bias are flagged and downweighted. This often involves consulting fact-checking databases such as Snopes, PolitiFact, and FactCheck.org to assess the credibility of sources.\n",
            "* **Inconsistent or Contradictory Statements within a Single Source:** Internal contradictions within a document are identified and resolved or flagged as unreliable.\n",
            "\n",
            "**2. Bayesian Methods for Probability Estimation:**  Probabilistic methods, such as Naive Bayes classifiers or Bayesian Networks, are used to assign probabilities to conflicting statements.  These methods incorporate prior probabilities reflecting the initial belief in the reliability of different sources (e.g., a news article from a reputable source might have a higher prior probability of accuracy than a social media post). For example, a Naive Bayes classifier might assign a probability of 0.8 to a statement from a trusted news source and 0.2 to a statement from an anonymous online forum. The specific prior probabilities are often learned from a training dataset of labeled information.\n",
            "\n",
            "**3. Ensemble Methods for Consensus Building:** Multiple models or sources are used to assess the information, and their outputs are combined using ensemble methods. The weights assigned to each model or source in the ensemble are determined by their performance on a validation set, often using metrics like accuracy or F1-score.  This could involve simple averaging, weighted averaging based on performance scores, or more sophisticated techniques like stacking or boosting.  A high agreement across multiple sources strengthens the confidence in the final output.\n",
            "\n",
            "**4. Continuous Learning and Feedback Mechanisms:** LLMs continuously learn and refine their ability to handle contradictions through feedback mechanisms. This may involve:\n",
            "\n",
            "* **Human-in-the-loop verification:** Human annotators review the model's output and provide feedback on its accuracy and reliability, allowing for iterative improvements in the model's handling of contradictions.\n",
            "* **Reinforcement learning:**  The model is trained using reinforcement learning techniques, receiving rewards for correctly resolving contradictions and penalties for incorrect resolutions. This helps the model learn to prioritize reliable sources and identify manipulative techniques.\n",
            "\n",
            "**5. Handling Unresolvable Contradictions:** In cases where contradictions remain unresolvable even after applying the above techniques, the LLM aims to present the conflicting information transparently to the user. This might involve:\n",
            "\n",
            "* **Presenting probabilities:** Instead of offering a definitive answer, the model presents the probabilities associated with each conflicting statement (e.g., \"Statement A has a probability of 0.55 of being true, while Statement B has a probability of 0.45\").  This acknowledges the uncertainty inherent in the situation.\n",
            "* **Flagging potential unreliability:** If the probabilities for both statements are low (e.g., 0.3 and 0.2), the model might explicitly flag both sources as potentially unreliable, highlighting the limitations of the available information.  Or, if the model's confidence is low, it may choose to abstain from providing a definite answer.\n",
            "\n",
            "By combining these techniques, LLMs strive to minimize the impact of contradictory information, producing more accurate and reliable outputs. However, it is crucial to remember that handling contradictions perfectly is a challenging problem, and complete resolution is not always possible.  The transparent presentation of uncertainty remains a key aspect of responsible LLM development.\n",
            "\n",
            "SecondOrator:This is an excellent, comprehensive explanation of how LLMs handle contradictory information.  It's clear, well-structured, and covers a wide range of techniques. Here are a few minor suggestions for improvement:\n",
            "\n",
            "* **Clarify \"prior probabilities\" in Bayesian methods:**  While you mention prior probabilities, briefly explaining what influences their assignment would be beneficial. For example, you could add a sentence like:  \"These prior probabilities are often derived from the training data, reflecting the observed reliability of different sources in that dataset.\"  This clarifies where these crucial values come from.\n",
            "\n",
            "* **Expand on Ensemble Methods:**  The explanation of ensemble methods is good, but adding a specific example would make it more concrete. For instance, you could mention that a system might combine the outputs of a fact-checking model, a sentiment analysis model, and a language model, weighting them based on their individual performance on a benchmark dataset.\n",
            "\n",
            "* **Specificity in Continuous Learning:**  The description of continuous learning is a bit general.  Adding a specific example of a feedback mechanism, such as a user interface where users can rate the accuracy of the model's responses, would strengthen this section.\n",
            "\n",
            "* **Nuance on Human-in-the-loop:**  Acknowledge the limitations of human-in-the-loop verification.  Human annotators are not infallible and can introduce bias.  A short sentence addressing this limitation would add balance.\n",
            "\n",
            "* **Consider adding a section on contextual understanding:** LLMs don't just look at individual statements in isolation.  Context plays a huge role.  A brief section on how context helps LLMs resolve or understand contradictions would be valuable. For example,  contradictions might be resolved by understanding temporal information (e.g., a statement might be true at one point in time but false later).\n",
            "\n",
            "\n",
            "Here's an example of how to incorporate some of these suggestions:\n",
            "\n",
            "**(Revised Section on Bayesian Methods):**\n",
            "\n",
            "\"**2. Bayesian Methods for Probability Estimation:** Probabilistic methods, such as Naive Bayes classifiers or Bayesian Networks, are used to assign probabilities to conflicting statements. These methods incorporate prior probabilities reflecting the initial belief in the reliability of different sources (e.g., a news article from a reputable source might have a higher prior probability of accuracy than a social media post). These prior probabilities are often derived from the training data, reflecting the observed reliability of different sources in that dataset. For example, a Naive Bayes classifier might assign a probability of 0.8 to a statement from a trusted news source and 0.2 to a statement from an anonymous online forum. The specific prior probabilities are often learned from a training dataset of labeled information.\"\n",
            "\n",
            "\n",
            "By incorporating these minor improvements, you can make an already excellent explanation even more robust and informative.\n",
            "\n",
            "round:6 over!\n",
            "round:7\n",
            "FirstOrator:You're right, these are excellent suggestions for improving the explanation of how LLMs handle contradictory information.  Let's incorporate them.  Since I don't have access to the original explanation, I'll provide a revised section incorporating your suggestions.  This assumes the original explanation already covers the core methods.\n",
            "\n",
            "\n",
            "**How Large Language Models Handle Contradictory Information**\n",
            "\n",
            "Large Language Models (LLMs) face the challenge of dealing with contradictory information frequently present in their training data and input prompts.  Several techniques are employed to mitigate this issue:\n",
            "\n",
            "**1.  Weighted Averaging:** A simple approach involves assigning weights to different sources based on perceived reliability.  Sources deemed more trustworthy (e.g., established news organizations) receive higher weights.  The final output is a weighted average of the conflicting statements, leaning towards the more reliable sources. However, this method is simplistic and struggles with nuanced contradictions.\n",
            "\n",
            "\n",
            "**2. Bayesian Methods for Probability Estimation:** Probabilistic methods, such as Naive Bayes classifiers or Bayesian Networks, are used to assign probabilities to conflicting statements.  These methods incorporate prior probabilities reflecting the initial belief in the reliability of different sources (e.g., a news article from a reputable source might have a higher prior probability of accuracy than a social media post).  These prior probabilities are often derived from the training data, reflecting the observed reliability of different sources in that dataset. For example, a Naive Bayes classifier might assign a probability of 0.8 to a statement from a trusted news source and 0.2 to a statement from an anonymous online forum.  The specific prior probabilities are often learned from a training dataset of labeled information.  The model then updates these probabilities based on the evidence presented in the current input.\n",
            "\n",
            "\n",
            "**3. Ensemble Methods:**  Ensemble methods combine the predictions of multiple models to improve accuracy and robustness. For instance, a system might combine the outputs of a fact-checking model, a sentiment analysis model, and a language model itself, weighting them based on their individual performance on a benchmark dataset.  The final output reflects a consensus or weighted average of these individual predictions, effectively reducing the impact of any single model's errors or biases.\n",
            "\n",
            "\n",
            "**4. Continuous Learning and Feedback Mechanisms:** LLMs can continuously learn and adapt to new information and feedback.  A key aspect is the incorporation of feedback mechanisms, such as user interfaces where users can rate the accuracy of the model's responses.  This feedback data is then used to refine the model's parameters and improve its ability to handle contradictions in the future.  The model might adjust its weights or priors based on user feedback, iteratively improving its performance.\n",
            "\n",
            "\n",
            "**5. Human-in-the-Loop Verification:** In critical applications, human oversight plays a crucial role.  Human annotators can review the model's output and resolve contradictions or ambiguities.  However, it's important to acknowledge that human annotators are not infallible and can introduce bias.  Careful selection and training of annotators, along with inter-annotator agreement checks, are essential for mitigating this risk.\n",
            "\n",
            "\n",
            "**6. Contextual Understanding:** LLMs don't treat statements in isolation.  Context is vital for resolving contradictions. For example, temporal information resolves apparent contradictions; a statement true in 2020 might be false in 2024.  Similarly, understanding the speaker's intent, the domain of discourse, and the overall narrative helps the LLM interpret contradictory information more accurately.  The LLM might use techniques like coreference resolution and relation extraction to identify the relationships between different statements and establish a coherent narrative that resolves the apparent contradictions.\n",
            "\n",
            "\n",
            "This revised explanation incorporates your suggestions, offering a more comprehensive and nuanced understanding of how LLMs tackle the challenge of contradictory information.  The added specificity and examples significantly enhance clarity and understanding.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 582.80ms\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TooManyRequests",
          "evalue": "429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTooManyRequests\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-19df24fb4540>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtopic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"請輸入題目：\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mLetsGoDebating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-79-bf0c594785e5>\u001b[0m in \u001b[0;36mLetsGoDebating\u001b[0;34m(topic)\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0mcurrent_row\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mSecondOrator_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFirstOrator_content\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"SecondOrator:{SecondOrator_content.text}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mDebatingData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSecondOrator_content\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Debate Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Create DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 response = self._client.generate_content(\n\u001b[0m\u001b[1;32m    332\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mrequest_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    836\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             )\n\u001b[0;32m--> 293\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             _retry_error_helper(\n\u001b[0m\u001b[1;32m    154\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         )\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1159\u001b[0m             \u001b[0;31m# subclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mcore_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0;31m# Return the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTooManyRequests\u001b[0m: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 總結\n",
        "我學到了甚麼呢?"
      ],
      "metadata": {
        "id": "jZmiLp_8IKVt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   一開始\n",
        "  *   創建兩個角色：把引入模型的指令用兩次，並分配給不同的model\n",
        "2.   辯論期間\n",
        "  *   使用f string來簡化文字輸入輸出\n",
        "  *   使用current row控制一開始的輸入位置，不然剛剛有發生從A1000開始輸入的情況\n",
        "  *   複習了把資料寫進google sheet是用\"set_with_dataframe\"的功能\n",
        "  *   使用pd.DataFrame把輸出文字轉成資料框\n",
        "  \n",
        "**心得**\n",
        "\n",
        "一開始我還打算先把全部的資料都記錄起來，再處理\n",
        "卻發生\"is not defined\"的問題，可能是因為整個過程都在外包函式內發生。所以我後來改變策略，決定及時紀錄，這樣子也比較直覺，好處理多了，也在我的free plan過期前，把檔案給做好了。\n",
        "\n",
        "**有趣的地方**\n",
        "\n",
        "這兩個模型後來就離題了，他們在討論這個\n",
        "\n",
        "SecondOrator:Okay, I understand.  Let's try something different.  Tell me about a time you had to overcome a significant challenge. What was the challenge, how did you approach it, and what did you learn from the experience?\n",
        "\n",
        "然後他們還知道自己是LLM，有趣"
      ],
      "metadata": {
        "id": "D3TsI0wrIXC0"
      }
    }
  ]
}